{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: Please run the 'LoadTwb' notebook before running this notebook\n",
    "\n",
    "##  This tool automates the extraction of metadata, from the tableau workbook, such as datasource,dimensions,measures, calcuated fields,parameters,etc. and load them into a standardized Excel workbook that will have sheets containing different types of data.\n",
    "\n",
    "## A large chunk of the code performs extraction, trasnformation and loading (ETL) from the structured XML file (.twb file)\n",
    "\n",
    "## This notebook excellently showcases use of list comprehensions, packages, nested for- loops,dictionaries and magic commands\n",
    "\n",
    "##  Output path for the Excel workbook needs to be modified in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing xml file (twb) into python\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "from itertools import chain,zip_longest\n",
    "\n",
    "%store -r fname\n",
    "%load fname\n",
    "\n",
    "tree = ET.parse(fname)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare variables\n",
    "\n",
    "workbook_names , database_names, table_names, server_names, datasource_alias, dashboard_names,schema_names, worksheet_names = ([] for _ in range(8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Datbase name\n",
    "\n",
    "def get_database_names():\n",
    "    \n",
    "    database_names = []\n",
    "    \n",
    "    #if query_flag == 0:\n",
    "        \n",
    "    for i in root.iter('named-connection'):\n",
    "        for j in i.iter('connection'):\n",
    "            database_names.append(j.get('dbname',default=''))\n",
    "        \n",
    "    return database_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Table names\n",
    "\n",
    "def get_table_names():\n",
    "    \n",
    "    table_names = []\n",
    "    \n",
    "    #Table names\n",
    "    for i in root.iter('relation'):\n",
    "        table_names.append(i.get('table',default=''))\n",
    "    \n",
    "    \n",
    "    table_names = [i.replace('[dbo].','') for i in table_names]\n",
    "    table_names = [i.replace('dbo.','') for i in table_names]\n",
    "    table_names = [i.replace('[','') for i in table_names]\n",
    "    table_names = [i.replace(']','') for i in table_names]\n",
    "    \n",
    "    \n",
    "    return table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get server names\n",
    "\n",
    "def get_server_names():\n",
    "    \n",
    "    server_names = []\n",
    "    \n",
    "    for i in root.iter('named-connection'):\n",
    "        for j in i.iter('connection'):            \n",
    "            server_names.append(j.get('server',default=''))\n",
    "                \n",
    "    return server_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get datasource alias\n",
    "\n",
    "def get_datasource_alias():\n",
    "    \n",
    "    datasource_alias = []\n",
    "    \n",
    "    for i in root.iter('datasource'):\n",
    "        \n",
    "        if i.get('caption') is not None:\n",
    "            datasource_alias.append(i.get('caption',default=''))\n",
    "        \n",
    "        else:\n",
    "            datasource_alias.append(i.get('name',default=''))\n",
    "                \n",
    "            \n",
    "    return datasource_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dashboard names\n",
    "\n",
    "def get_dashboard_names():\n",
    "    \n",
    "    dashboard_names = []\n",
    "    \n",
    "    for i in root.iter('dashboard'):\n",
    "        dashboard_names.append(i.get('name',default=''))\n",
    "    \n",
    "    return dashboard_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get workbook name\n",
    "\n",
    "def get_workbook_names():\n",
    "    \n",
    "    workbook_names = []\n",
    "    \n",
    "    fname_wo_ext = fname[:-4]  # remove twb\n",
    "\n",
    "    slash_pos = fname_wo_ext.rfind('/')  # extract file name\n",
    "\n",
    "    wrbk_name = fname_wo_ext[slash_pos+1:]\n",
    "    \n",
    "    workbook_names.append(wrbk_name)\n",
    "        \n",
    "    return workbook_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get worksheet name\n",
    "\n",
    "def  get_worksheet_names():\n",
    "    \n",
    "    worksheet_names = []\n",
    "    \n",
    "    for i in root.iter('worksheet'):\n",
    "        worksheet_names.append(i.get('name',default=''))\n",
    "        \n",
    "    return worksheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From here, the code essentially writes the extracted metadata into specific excel tabs/sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive Summary Tab\n",
    "\n",
    "ex_desc = []\n",
    "kpi = []\n",
    "tableau_version = []\n",
    "dashboard_published_not_published = []\n",
    "\n",
    "#Dashboard names\n",
    "dashboard_names = get_dashboard_names()    \n",
    "#print(dashboard_names)\n",
    "\n",
    "# workbook names\n",
    "workbook_names = get_workbook_names()    \n",
    "#print(workbook_names)\n",
    "\n",
    "#Ex_Description  #Kpi #Tableau version\n",
    "ex_desc.append('')\n",
    "kpi.append('')\n",
    "    \n",
    "for i in root.iter('workbook'):    \n",
    "    tableau_version.append(i.get('version',default=''))   \n",
    "\n",
    "#print(tableau_version)\n",
    "\n",
    "zip_list = zip_longest(workbook_names,dashboard_names,ex_desc,kpi,tableau_version,dashboard_published_not_published,\n",
    "                      fillvalue = '')\n",
    "\n",
    "df_exec_sumry = pd.DataFrame(zip_list, columns = ['Workbook','Dashboard','Ex_Description','Key_Performance_Indicators',\n",
    "                                                  'Tableau_Version','Dashboard_Published_Non-Published'])\n",
    "\n",
    "df_exec_sumry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Source tab\n",
    "\n",
    "custom_sql_query = []\n",
    "connection_type = []\n",
    "sql_query_flag = 0\n",
    "table_view = []\n",
    "data_source_path = []\n",
    "zip_list = []\n",
    "t_names = []\n",
    "\n",
    "\n",
    "    #Custom SQL query\n",
    "for i in root.iter('connection'):\n",
    "    for j in i.iter('relation'):\n",
    "        if j.get('type') == 'text':\n",
    "            sql_query_flag = 1  \n",
    "            #print(\"Custom SQL exists!\",'\\n\\n')\n",
    "            custom_sql_query.append(j.text)\n",
    "\n",
    "        else:   \n",
    "            custom_sql_query.append('')\n",
    "\n",
    "#Table names\n",
    "\n",
    "table_names = get_table_names()\n",
    "#print(table_names)\n",
    "\n",
    "\n",
    " #Database names\n",
    "\n",
    "database_names = get_database_names()\n",
    "#print(database_names)\n",
    "\n",
    "\n",
    "#Server names  \n",
    "server_names = get_server_names()\n",
    "#print(server_names)\n",
    "\n",
    "#Schema name\n",
    "\n",
    "for i in root.iter('relation'):\n",
    "    t_names.append(i.get('table',default=''))\n",
    "\n",
    "for i in t_names:\n",
    "    schema_names.append(re.findall('^(\\[\\w+\\]).',i, flags=re.IGNORECASE))\n",
    "\n",
    "schema_names = list(chain.from_iterable(schema_names))\n",
    "\n",
    "schema_names = [i.replace('[','') for i in schema_names]\n",
    "schema_names = [i.replace(']','') for i in schema_names]\n",
    "#print(schema_names)\n",
    "\n",
    "#Datasource caption\n",
    "datasource_alias = get_datasource_alias()\n",
    "#print(datasource_alias)\n",
    "\n",
    "\n",
    "# workbook names\n",
    "workbook_names = get_workbook_names()    \n",
    "#print(workbook_names)\n",
    "\n",
    "#Connection_Type\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "zip_list = zip_longest(workbook_names,server_names,database_names,schema_names,table_names,table_view,custom_sql_query,\n",
    "                       connection_type,datasource_alias,data_source_path,fillvalue = '')\n",
    "\n",
    "df_datasource = pd.DataFrame(zip_list, columns = ['Workbook','Server_Name','Database_Name','Schema_Name',\n",
    "                                                  'Table_Name','Table_View','Custom_SQL','Connection_Type',\n",
    "                                                  'Data_Source_Alias','Data_Source_Path'])\n",
    "\n",
    "df_datasource = df_datasource.drop_duplicates()\n",
    "\n",
    "df_datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Worksheet tab\n",
    "\n",
    "used = []\n",
    "worksheet_desc = []\n",
    "unused_worksheet_names = []\n",
    "all_worksheet_names = []\n",
    "dashboard_names = []\n",
    "worksheet_names = []\n",
    "\n",
    "for i in root.iter('window'):\n",
    "    \n",
    "    if i.get('class') == 'dashboard':\n",
    "        \n",
    "        for j in i[0].iter('viewpoint'):                            # [] helps pick only specific child nodes\n",
    "            dashboard_names.append(i.get('name',default=''))\n",
    "            worksheet_names.append(j.get('name',default = ''))\n",
    "\n",
    "            \n",
    "for i in root.iter('worksheet'):\n",
    "    all_worksheet_names.append(i.get('name',default=''))\n",
    "    \n",
    "all_worksheet_names = set(all_worksheet_names)\n",
    "        \n",
    "\n",
    "# workbook names\n",
    "workbook_names = get_workbook_names()\n",
    "    \n",
    "zip_list = zip_longest(workbook_names,dashboard_names,worksheet_names,used,worksheet_desc,\n",
    "                      fillvalue = '')\n",
    "\n",
    "df_used = pd.DataFrame(zip_list, columns = ['Workbook','Dashboard','Worksheet','Used','Worksheet_Description'])\n",
    "\n",
    "# Take non-matching names between used and all worksheets\n",
    "unused_worksheet_names = all_worksheet_names.symmetric_difference(set(df_used['Worksheet']))\n",
    "\n",
    "df_unused = pd.DataFrame(unused_worksheet_names,columns = ['Worksheet'])\n",
    "\n",
    "df_worksheet = pd.concat([df_used,df_unused], sort = False).fillna('')\n",
    "\n",
    "df_worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields and Tables tab\n",
    "\n",
    "# Datasource field names\n",
    "datasource_field_names = []\n",
    "tableau_field_names = []\n",
    "measure_dimension = []\n",
    "data_type = []\n",
    "used = []\n",
    "sql_calcs = []\n",
    "original_field_name = []\n",
    "tableau_fnames = []\n",
    "local_field_names = []\n",
    "local_field_type = []\n",
    "meas_dim = []\n",
    "dashboard_names = []\n",
    "worksheet_temp_col = []\n",
    "\n",
    "\n",
    "\n",
    "for i in root.iter('worksheet'):\n",
    "\n",
    "    for col_info in i.iter('column'):\n",
    "    \n",
    "        if col_info.find('calculation') is None:\n",
    "        \n",
    "            if col_info.get('caption') is not None or col_info.get('name') is not None:\n",
    "\n",
    "                if col_info.get('caption') is not None:\n",
    "\n",
    "                    tableau_field_names.append(col_info.get('caption',default=''))\n",
    "\n",
    "                else:\n",
    "                    tableau_field_names.append(col_info.get('name',default=''))\n",
    "\n",
    "                worksheet_temp_col.append(i.get('name',default = ''))    \n",
    "\n",
    "                datasource_field_names.append(col_info.get('name',default=''))\n",
    "\n",
    "                measure_dimension.append(col_info.get('role',default=''))\n",
    "\n",
    "                data_type.append(col_info.get('datatype',default=''))\n",
    "\n",
    "\n",
    "# workbook names \n",
    "workbook_names = get_workbook_names()\n",
    "\n",
    "#Server names  \n",
    "server_names = get_server_names()\n",
    "            \n",
    "#Table names    \n",
    "table_names = get_table_names()\n",
    "\n",
    "\n",
    "#Database names\n",
    "database_names = get_database_names()\n",
    "\n",
    "\n",
    "#Fixing missing fields    \n",
    "for i in root.iter('metadata-record'):\n",
    "    \n",
    "    for j in i.iter('local-name'):\n",
    "        \n",
    "        local_field_names.append(j.text)\n",
    "\n",
    "        \n",
    "    for l in i.iter('local-type'):\n",
    "        \n",
    "        local_field_type.append(l.text)\n",
    "\n",
    "\n",
    "for i in local_field_type:\n",
    "    \n",
    "    if i in ('string','datetime','boolean'):\n",
    "        \n",
    "        meas_dim.append('dimension')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        meas_dim.append('measure')\n",
    "\n",
    "\n",
    "tableau_fnames = [i for i in local_field_names]        \n",
    "# find missing elements and create a list\n",
    "\n",
    "\n",
    "zip_list = zip_longest(workbook_names,dashboard_names,worksheet_temp_col,tableau_field_names,datasource_field_names,table_names,database_names,\n",
    "               server_names,data_type,used,measure_dimension,sql_calcs,original_field_name,\n",
    "                      fillvalue = '')\n",
    "\n",
    "df1 = pd.DataFrame(zip_list, columns =  ['Workbook','Dashboard','Worksheet_Temp_Col','Tableau_Field_Name','Datasource_Field_Name',\n",
    "                                                      'Table_Name','Database_Name','Server_Name','Data_Type','Used',\n",
    "                                                      'Dimension_Measure','SQL_Calculations','Original_Field_Name'])\n",
    "\n",
    "\n",
    "zip_union_list = zip_longest(tableau_fnames,local_field_names,meas_dim,local_field_type,fillvalue = '')\n",
    "\n",
    "df2 = pd.DataFrame(zip_union_list,columns = ['Tableau_Field_Name','Datasource_Field_Name','Dimension_Measure','Data_Type'])\n",
    "\n",
    "df2.drop_duplicates()\n",
    "\n",
    "df_fields_tables = pd.concat([df1,df2],sort = False)\n",
    "\n",
    "df_fields_tables = df_fields_tables.fillna('')\n",
    "\n",
    "\n",
    "# Dashboard names\n",
    "\n",
    "\n",
    "#  Fields used directly in dashboard\n",
    "for row,col in df_fields_tables.iterrows():\n",
    "               \n",
    "    for a,b in df_worksheet.iterrows():\n",
    "        \n",
    "        if col['Worksheet_Temp_Col'] == b['Worksheet']:\n",
    "            \n",
    "            df_fields_tables.iat[row,1] = b['Dashboard']\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "df_fields_tables = df_fields_tables.drop(['Worksheet_Temp_Col'], axis = 1)\n",
    "                        \n",
    "    \n",
    "# Fields used through calc formulas is performed in the end of cell for df_calc_fields   \n",
    "    \n",
    "     \n",
    "# The below output is not final, part of operation is performed later\n",
    "df_fields_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculated Fields tab\n",
    "\n",
    "\n",
    "# ----------------------Capture calculated fields-------------------------------\n",
    "\n",
    "calculated_field_names = []\n",
    "calculated_field_formulas = []\n",
    "measure_dimension = []\n",
    "calc_ids = []\n",
    "param_ids  = []\n",
    "fields_used = []\n",
    "used = []\n",
    "calc_type = []\n",
    "\n",
    "calculated_field_names_2 = []\n",
    "calculated_field_formulas_2 = []\n",
    "measure_dimension_2 = []\n",
    "calc_ids_2 = []\n",
    "param_ids_2 = []\n",
    "fields_used_2 = []\n",
    "\n",
    "calc_captions = {}\n",
    "param_captions = {}\n",
    "\n",
    "calc_captions_2 = {}\n",
    "param_captions_2 = {}\n",
    "\n",
    "dashboard_names = []\n",
    "worksheet_temp_col = []\n",
    "\n",
    "formulas_wo_comments = []\n",
    "formulas_wo_comments_2 = []\n",
    "\n",
    "#Function to unnest a list as a result of re operations and also filter unique values using set\n",
    "\n",
    "def unnest_and_set(some_list):   \n",
    "    unnested_lst = list(chain.from_iterable(some_list))\n",
    "\n",
    "    unnested_lst_set = set(unnested_lst)\n",
    "\n",
    "    lst_with_unique_elems = list(unnested_lst_set)\n",
    "    \n",
    "    return lst_with_unique_elems\n",
    "\n",
    "\n",
    "\n",
    "#Capture contents of a calculated field on a worksheet basis\n",
    "\n",
    "#-------- Making changes here to test if worksheet col needs to be added prior to\n",
    "\n",
    "for i in root.iter('worksheet'):\n",
    "\n",
    "    for col_info in i.iter('column'):\n",
    "\n",
    "        #Avoid capturing parameters along with calc fields\n",
    "        if col_info.find('calculation') is not None and col_info.get('param-domain-type') is None:  \n",
    "\n",
    "            if col_info.get('caption'):\n",
    "                \n",
    "                worksheet_temp_col.append(i.get('name',default = ''))\n",
    "                calculated_field_names.append(col_info.get('caption',default=''))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                worksheet_temp_col.append(i.get('name',default = ''))\n",
    "                calculated_field_names.append(col_info.get('name',default=''))\n",
    "\n",
    "\n",
    "            for formula_info in col_info.iter('calculation'):\n",
    "\n",
    "                calculated_field_formulas.append(formula_info.get('formula',default=''))          \n",
    "\n",
    "            measure_dimension.append(col_info.get('role',default=''))\n",
    "\n",
    "        \n",
    "# Capture calc fields not used in any worksheets aka unused calc fields     \n",
    "\n",
    "for k in root.iter('column'):\n",
    "\n",
    "        #Avoid capturing parameters along with calc fields\n",
    "        if k.find('calculation') is not None and k.get('param-domain-type') is None:  \n",
    "\n",
    "            if k.get('caption'):\n",
    "                \n",
    "                calculated_field_names_2.append(k.get('caption',default=''))\n",
    "\n",
    "            else:\n",
    "                \n",
    "                calculated_field_names_2.append(k.get('name',default=''))\n",
    "\n",
    "            for l in k.iter('calculation'):\n",
    "\n",
    "                calculated_field_formulas_2.append(l.get('formula',default=''))          \n",
    "\n",
    "            measure_dimension_2.append(k.get('role',default=''))\n",
    "            \n",
    "            \n",
    "# Capture calculation ids inside of other calculations\n",
    "for elems in calculated_field_formulas:\n",
    "    \n",
    "    calc_ids.append(re.findall('\\[Calculation_.*?\\]',elems))\n",
    "    param_ids.append(re.findall('\\[Parameter .*?\\]',elems))    \n",
    "\n",
    "calc_ids = unnest_and_set(calc_ids)\n",
    "param_ids = unnest_and_set(param_ids)\n",
    "\n",
    "\n",
    "for elems_2 in calculated_field_formulas_2:\n",
    "    \n",
    "    calc_ids_2.append(re.findall('\\[Calculation_.*?\\]',elems_2))\n",
    "    param_ids_2.append(re.findall('\\[Parameter .*?\\]',elems_2))    \n",
    "\n",
    "calc_ids_2 = unnest_and_set(calc_ids_2)\n",
    "param_ids_2 = unnest_and_set(param_ids_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find the names of calculated fields corresponding to the calculation ids and create a dictionary off of it\n",
    "for elem in calc_ids:\n",
    "    \n",
    "    for child in root.iter('column'):\n",
    "        \n",
    "        calc_name = child.get('name',default='')\n",
    "        calc_caption = child.get('caption',default='')\n",
    "        \n",
    "        if calc_name == elem:\n",
    "            \n",
    "            calc_captions[elem] = calc_caption\n",
    "\n",
    "# ------\n",
    "\n",
    "for elem_2 in calc_ids_2:\n",
    "    \n",
    "    for child_2 in root.iter('column'):\n",
    "        \n",
    "        calc_name_2 = child_2.get('name',default='')\n",
    "        calc_caption_2 = child_2.get('caption',default='')\n",
    "        \n",
    "        if calc_name_2 == elem_2:\n",
    "            \n",
    "            calc_captions_2[elem_2] = calc_caption_2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "# Find the names of parameters corresponding to the paramerer ids and create a dictionary off of it\n",
    "for elem in param_ids:\n",
    "    \n",
    "    for child in root.iter('column'):\n",
    "        \n",
    "        param_name = child.get('name',default='')\n",
    "        param_caption = child.get('caption',default='')\n",
    "        \n",
    "        if param_name == elem:\n",
    "            \n",
    "            param_captions[elem] = param_caption\n",
    "    \n",
    "\n",
    "    \n",
    "for elem_2 in param_ids_2:\n",
    "    \n",
    "    for child_2 in root.iter('column'):\n",
    "        \n",
    "        param_name_2 = child_2.get('name',default='')\n",
    "        param_caption_2 = child_2.get('caption',default='')\n",
    "        \n",
    "        if param_name_2 == elem_2:\n",
    "            \n",
    "            param_captions_2[elem_2] = param_caption_2    \n",
    "    \n",
    "    \n",
    "#print(param_captions,'\\n\\n')    \n",
    "    \n",
    "#Replace calculation ids with actual names using list comprehensions\n",
    "for key in calc_captions:\n",
    "\n",
    "    calculated_field_formulas = [strs.replace(key,calc_captions[key]) for strs in calculated_field_formulas]  \n",
    "\n",
    "\n",
    "    \n",
    "for key in param_captions:\n",
    "    \n",
    "    calculated_field_formulas = [strs.replace(key,param_captions[key]) for strs in calculated_field_formulas]    \n",
    "    \n",
    "    \n",
    "for key in calc_captions_2:\n",
    "\n",
    "    calculated_field_formulas_2 = [strs.replace(key,calc_captions_2[key]) for strs in calculated_field_formulas_2]  \n",
    "\n",
    "\n",
    "    \n",
    "for key in param_captions_2:\n",
    "    \n",
    "    calculated_field_formulas_2 = [strs.replace(key,param_captions_2[key]) for strs in calculated_field_formulas_2]\n",
    "\n",
    "    \n",
    "#Fields used\n",
    "\n",
    "combo_list = []\n",
    "\n",
    "#combo_list = tableau_field_names + datasource_field_names + calculated_field_names\n",
    "\n",
    "combo_list = list(df_fields_tables['Tableau_Field_Name']) + list(df_fields_tables['Datasource_Field_Name']) + calculated_field_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Creating a new list of calc field formulas with // removed for scanning fields used accurately\n",
    "\n",
    "for i in calculated_field_formulas:\n",
    "    \n",
    "    i = i.strip()\n",
    "    \n",
    "    if \"//\" in i:\n",
    "        \n",
    "        pos = i.index('//')\n",
    "    \n",
    "        formulas_wo_comments.append(i[:pos])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        formulas_wo_comments.append(i)\n",
    "\n",
    "#---        \n",
    "for j in calculated_field_formulas_2:\n",
    "    \n",
    "    j = j.strip()\n",
    "    \n",
    "    if \"//\" in j:\n",
    "        \n",
    "        pos2 = j.index('//')\n",
    "    \n",
    "        formulas_wo_comments_2.append(j[:pos2])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        formulas_wo_comments_2.append(j)\n",
    "\n",
    "\n",
    "\n",
    "for text in formulas_wo_comments:\n",
    "\n",
    "    fields_used.append([field for field in combo_list if field in text])\n",
    "\n",
    "fields_used = [list(set(i)) for i in fields_used]\n",
    "\n",
    "fields_used = [str(i) for i in fields_used]\n",
    "\n",
    "fields_used = [i.replace(',',';') for i in fields_used]\n",
    "\n",
    "#----\n",
    "\n",
    "for text_2 in formulas_wo_comments_2:\n",
    "\n",
    "    fields_used_2.append([field_2 for field_2 in combo_list if field_2 in text_2])\n",
    "\n",
    "fields_used_2 = [list(set(i)) for i in fields_used_2]\n",
    "\n",
    "fields_used_2 = [str(i) for i in fields_used_2]\n",
    "\n",
    "fields_used_2 = [i.replace(',',';') for i in fields_used_2]\n",
    "\n",
    "\n",
    "#Workbook names\n",
    "workbook_names = get_workbook_names()\n",
    "\n",
    "\n",
    "\n",
    "# Use zip function to create a dictionary of all the three columns\n",
    "calc_fields = zip_longest(workbook_names,dashboard_names,worksheet_temp_col,calculated_field_names,measure_dimension,\n",
    "                          calculated_field_formulas,fields_used,used,calc_type,\n",
    "                          fillvalue = '')\n",
    "\n",
    "df_calc_fields = pd.DataFrame(calc_fields, columns =  ['Workbook','Dashboard','Worksheet_Temp_Col','Calculated_Field_Name','Tableau_Field_Type',\n",
    "                                                       'Metric_Description','Fields_Used','Used','Calculation_Type'])\n",
    "\n",
    "\n",
    "calc_fields_2 = zip_longest(calculated_field_names_2,measure_dimension_2,\n",
    "                           calculated_field_formulas_2,fields_used_2,\n",
    "                           fillvalue = '')\n",
    "\n",
    "df_calc_fields_2 = pd.DataFrame(calc_fields_2, columns =  ['Calculated_Field_Name','Tableau_Field_Type',\n",
    "                                                           'Metric_Description','Fields_Used'])\n",
    "\n",
    "df_calc_fields_2 = df_calc_fields_2.drop_duplicates(subset = ['Calculated_Field_Name'])\n",
    "#Dashboard names\n",
    "\n",
    "                            \n",
    "for row,col in df_calc_fields.iterrows():\n",
    "               \n",
    "    for a,b in df_worksheet.iterrows():\n",
    "        \n",
    "        if col['Worksheet_Temp_Col'] == b['Worksheet']:\n",
    "            \n",
    "            df_calc_fields.iat[row,1] = b['Dashboard']\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "df_calc_fields = df_calc_fields.drop(['Worksheet_Temp_Col'], axis = 1)\n",
    "\n",
    "# Combine dfs\n",
    "df_calc_fields = pd.concat([df_calc_fields,df_calc_fields_2], sort = False).fillna('')\n",
    "\n",
    "\n",
    "    # Used in calc_formulas\n",
    "\n",
    "for row,col in df_calc_fields.iterrows():\n",
    "    \n",
    "    for a,b in df_calc_fields.iterrows():\n",
    "        \n",
    "        if col['Dashboard'] == '' and b['Dashboard']!= '':\n",
    "\n",
    "            if col['Calculated_Field_Name'] in b['Fields_Used']:\n",
    "\n",
    "                df_calc_fields.iat[row,1] = b['Dashboard']\n",
    "\n",
    "\n",
    "df_calc_fields = df_calc_fields.drop_duplicates(subset = ['Dashboard','Calculated_Field_Name'])\n",
    "\n",
    "\n",
    "# continued from df_fields_tables . Dashboard names for df_fields_tables\n",
    "\n",
    "for row,col in df_fields_tables.iterrows():\n",
    "    \n",
    "    for a,b in df_calc_fields.iterrows():\n",
    "        \n",
    "        if b['Dashboard'] != '' and col['Dashboard'] == '':\n",
    "            \n",
    "            if col['Tableau_Field_Name'] in b['Fields_Used'] or col['Datasource_Field_Name'] in b['Fields_Used']:\n",
    "                \n",
    "                df_fields_tables.iat[row,1] = b['Dashboard']\n",
    "                \n",
    "\n",
    "df_fields_tables = df_fields_tables.drop_duplicates(subset = ['Dashboard','Datasource_Field_Name'])       \n",
    "\n",
    "df_calc_fields = df_calc_fields.drop_duplicates(subset = ['Dashboard','Calculated_Field_Name'])\n",
    "\n",
    "df_calc_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters tab\n",
    "\n",
    "#Filter_name\n",
    "\n",
    "filter_names_raw = []\n",
    "filter_names_raw2 = []\n",
    "filter_names = []\n",
    "filter_names_full = []\n",
    "calc_ids = []\n",
    "some_list = []\n",
    "calc_captions = {}\n",
    "filter_action = []\n",
    "fields_used = []\n",
    "sheet_name = []\n",
    "dashboard_names = []\n",
    "worksheet_temp_col = []  # Capture worksheet names to further capture dashboard names, choose to keep or drop this column after the fact\n",
    "\n",
    "#Worksheet filters\n",
    "\n",
    "for i in root.iter('worksheet'):\n",
    "    \n",
    "    for j in i.iter('slices'):\n",
    "    \n",
    "        for k in j.iter('column'):\n",
    "    \n",
    "            filter_names_full.append(k.text)\n",
    "            worksheet_temp_col.append(i.get('name',default = ''))\n",
    "\n",
    "\n",
    "\n",
    "for i in filter_names_full:\n",
    "    \n",
    "    filter_names_raw.append(re.findall('.(\\[.*\\])',i))\n",
    "    \n",
    "\n",
    "filter_names_raw = list(chain.from_iterable(filter_names_raw))\n",
    "#print(filter_names_raw)\n",
    "\n",
    "\n",
    "for i in filter_names_raw:\n",
    "    \n",
    "    filter_names_raw2.append(re.sub('\\[\\w+:','[',i))\n",
    "\n",
    "\n",
    "for i in filter_names_raw2:\n",
    "    \n",
    "    filter_names.append(re.sub(':\\w+\\]',']',i))\n",
    "\n",
    "    \n",
    "#print('Filter_names: ',filter_names,'\\n\\n')\n",
    "    \n",
    "for i in filter_names:\n",
    "    \n",
    "    calc_ids.append(re.findall('.*(\\[Calculation_.*\\]).*',i,flags = re.IGNORECASE))\n",
    "\n",
    "\n",
    "calc_ids = unnest_and_set(calc_ids)\n",
    "\n",
    "#print('Calc ids: ',calc_ids,'\\n\\n')\n",
    "\n",
    "# Find the names of calculated fields corresponding to the calculation ids and create a dictionary off of it\n",
    "for elem in calc_ids:\n",
    "    \n",
    "    for child in root.iter('column'):\n",
    "        \n",
    "        calc_name = child.get('name',default='')\n",
    "        calc_caption = child.get('caption',default='')\n",
    "        \n",
    "        if calc_name == elem:\n",
    "            \n",
    "            calc_captions[elem] = calc_caption\n",
    "            \n",
    "            \n",
    "#print('Calc captions: ',calc_captions,'\\n\\n')\n",
    "\n",
    "        \n",
    "for key in calc_captions:        \n",
    "\n",
    "    filter_names = [strs.replace(key,calc_captions[key]) for strs in filter_names]\n",
    "        \n",
    "\n",
    "#filter_names = list(set(filter_names))\n",
    "#print('Filter names: ',filter_names,'\\n\\n')    \n",
    "\n",
    "#filter_names = [i.replace('[','') for i in filter_names]\n",
    "#filter_names = [i.replace(']','') for i in filter_names]    \n",
    "\n",
    "\n",
    "#Workbook names\n",
    "workbook_names = get_workbook_names()\n",
    "\n",
    "\n",
    "filter_action.append('Selected')\n",
    "                            \n",
    "                            \n",
    "        \n",
    "zip_list = zip_longest(workbook_names,dashboard_names,worksheet_temp_col,filter_names,filter_action,fields_used,sheet_name,\n",
    "                   fillvalue = '')\n",
    "\n",
    "df_filters = pd.DataFrame(zip_list, columns =  ['Workbook','Dashboard','Worksheet_Temp_Col','Filter_Name','Filter_Action','Fields_Used','Sheet_Name'])\n",
    "\n",
    "\n",
    "#Dashboard names\n",
    "\n",
    "#  Filters used directly in dashboard\n",
    "\n",
    "for row,col in df_filters.iterrows():\n",
    "               \n",
    "    for a,b in df_worksheet.iterrows():\n",
    "        \n",
    "        if col['Dashboard'] == '' and b['Dashboard'] != '':\n",
    "            \n",
    "            if col['Worksheet_Temp_Col'] == b['Worksheet']:\n",
    "\n",
    "                df_filters.iat[row,1] = b['Dashboard']\n",
    "\n",
    "\n",
    "df_filters = df_filters.drop(['Worksheet_Temp_Col'], axis = 1)\n",
    "\n",
    "\n",
    "df_filters = df_filters.drop_duplicates(subset = ['Dashboard','Filter_Name'])  #remove this if you want to capture data across worksheets and not just across workbook\n",
    "\n",
    "df_filters       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actions tab\n",
    "\n",
    "action_names = []\n",
    "source_sheet = []\n",
    "target_sheet = []\n",
    "run_action_on = []\n",
    "target_filter = []\n",
    "action_description = []\n",
    "worksheet_dashboard = []\n",
    "dashboard_names = []\n",
    "\n",
    "#Action Data\n",
    "for i in root.iter('action'):\n",
    "    \n",
    "    action_names.append(i.get('caption',default=''))\n",
    "\n",
    "#target sheet and source sheet is giving duplicate data. need to fix this\n",
    "    for j in i.iter('source'):\n",
    "        \n",
    "        source_sheet.append(j.get('worksheet',default=''))\n",
    "        dashboard_names.append(j.get('dashboard', default=''))\n",
    "    \n",
    "    for j in i.iter('activation'):\n",
    "        \n",
    "        run_action_on.append(j.get('type',default=''))\n",
    "    \n",
    "    \n",
    "#Workbook names\n",
    "workbook_names = get_workbook_names()\n",
    "   \n",
    "\n",
    "# Use zip function to create a dictionary of all columns\n",
    "zip_list = zip_longest(workbook_names,dashboard_names,action_names,source_sheet,target_sheet,run_action_on,target_filter,action_description,\n",
    "                       worksheet_dashboard,fillvalue = '')\n",
    "\n",
    "df_actions = pd.DataFrame(zip_list, columns =  ['Workbook','Dashboard','Action_Name','Source_Sheet',\n",
    "                                                    'Target_Sheet','Run_Action_On','Target_Filter',\n",
    "                                               'Action_Description','Worksheet_Dashboard'])\n",
    "\n",
    "df_actions = df_actions.drop_duplicates()  \n",
    "df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "parameter_name = []\n",
    "data_type = []\n",
    "allowable_value_type = []\n",
    "param_desc = []\n",
    "fields_used = []\n",
    "used = []\n",
    "wrksht_temp_col = []\n",
    "\n",
    "parameter_name_2 = []\n",
    "data_type_2 = []\n",
    "allowable_value_type_2 = []\n",
    "\n",
    "for i in root.iter('worksheet'):\n",
    "\n",
    "    for j in i.iter('column'):\n",
    "    \n",
    "        if j.get('param-domain-type') is not None:\n",
    "        \n",
    "            wrksht_temp_col.append(i.get('name',default=''))\n",
    "            \n",
    "            parameter_name.append(j.get('caption',default=''))\n",
    "            data_type.append(j.get('datatype',default=''))\n",
    "            allowable_value_type.append(j.get('param-domain-type',default=''))\n",
    "\n",
    "\n",
    "            \n",
    "for k in root.iter('column'):\n",
    "    \n",
    "    if k.get('param-domain-type') is not None:\n",
    "        \n",
    "        parameter_name_2.append(k.get('caption',default=''))\n",
    "        data_type_2.append(k.get('datatype',default=''))\n",
    "        allowable_value_type_2.append(k.get('param-domain-type',default=''))\n",
    "        \n",
    "        \n",
    "#Workbook names\n",
    "workbook_names = get_workbook_names()        \n",
    "\n",
    "\n",
    "# Create df\n",
    "zip_list = zip_longest(workbook_names, dashboard_names, wrksht_temp_col, parameter_name, data_type, allowable_value_type,param_desc,fields_used,used,\n",
    "                      fillvalue = '')\n",
    "\n",
    "df_parameters = pd.DataFrame(zip_list, columns = ['Workbook','Dashboard','Wrksht_Temp_Col','Parameter_Name','Data_Type',\n",
    "                                                  'Allowable_Value_Type','Parameter_Description','Fields_Used','Used'])\n",
    "\n",
    "\n",
    "\n",
    "zip_list_2 = zip_longest(parameter_name_2, data_type_2, allowable_value_type_2,\n",
    "                         fillvalue = '')\n",
    "\n",
    "df_parameters_2 = pd.DataFrame(zip_list_2, columns = ['Parameter_Name','Data_Type','Allowable_Value_Type'])\n",
    "\n",
    "df_parameters_2 = df_parameters_2.drop_duplicates(subset = ['Parameter_Name'])\n",
    "\n",
    "#Dashboard names\n",
    "\n",
    "\n",
    "for row,col in df_parameters.iterrows():\n",
    "    \n",
    "    for a,b in df_worksheet.iterrows():\n",
    "        \n",
    "        if col['Wrksht_Temp_Col'] == b['Worksheet']:\n",
    "            \n",
    "            df_parameters.iat[row,1] = b['Dashboard']\n",
    "            \n",
    "\n",
    "df_parameters = df_parameters.drop(['Wrksht_Temp_Col'], axis = 1)\n",
    "\n",
    "df_parameters = pd.concat([df_parameters,df_parameters_2], sort = False).fillna('')\n",
    "\n",
    "df_parameters = df_parameters.drop_duplicates(subset = ['Dashboard','Parameter_Name'])\n",
    "\n",
    "df_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh Schedule tab\n",
    "\n",
    "ref_sched = []\n",
    "ref_type = []\n",
    "\n",
    "#Workbook names\n",
    "\n",
    "# workbook names #Capture workbook names as many times as number of calc fields\n",
    "workbook_names = get_workbook_names()\n",
    "        \n",
    "        \n",
    "#Datasource caption\n",
    "datasource_alias = get_datasource_alias()            \n",
    "            \n",
    "\n",
    "    \n",
    "zip_list = zip_longest(workbook_names, ref_type, ref_sched, datasource_alias,\n",
    "                      fillvalue = '')\n",
    "\n",
    "df_refresh_schedule = pd.DataFrame(zip_list, columns = ['Workbook','Refresh_Type','Refresh_Schedule','Data_Source_Alias'])\n",
    "\n",
    "df_refresh_schedule = df_refresh_schedule.drop_duplicates()\n",
    "\n",
    "df_refresh_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unused fileds tab\n",
    "\n",
    "\n",
    "#Workbook names\n",
    "\n",
    "workbook_names = get_workbook_names()\n",
    "        \n",
    "\n",
    "#Datasource caption\n",
    "datasource_alias = get_datasource_alias()\n",
    "\n",
    "      \n",
    "        \n",
    "tableau_field_name = []\n",
    "field_type = []\n",
    "\n",
    "    \n",
    "zip_list = zip_longest(workbook_names, datasource_alias, tableau_field_name, field_type,\n",
    "                      fillvalue = '')\n",
    "\n",
    "df_unused_fields = pd.DataFrame(zip_list, columns = ['Workbook','Data_Source_Alias','Tableau_Field_Name',\n",
    "                                                  'Field_Type'])\n",
    "\n",
    "df_unused_fields = df_unused_fields.drop_duplicates()\n",
    "\n",
    "df_unused_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- Write to excel---------------------\n",
    "\n",
    "from openpyxl.styles import PatternFill\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "excel_path = r'C:\\Users............\\\\'    # Change this path to some local folder\n",
    "\n",
    "excel_path += input(\"Enter output file name: \")\n",
    "\n",
    "excel_path += '.xlsx'\n",
    "\n",
    "df_exec_sumry.to_excel(excel_path, sheet_name = 'Executive Summary', index = False)\n",
    "\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a') as writer:\n",
    "    df_datasource.to_excel(writer, sheet_name = 'Data Source',index = False)        #Write to specific location\n",
    "    df_worksheet.to_excel(writer, sheet_name = 'Worksheet',index = False)\n",
    "    df_fields_tables.to_excel(writer, sheet_name = 'Fields and Tables',index = False)\n",
    "    df_calc_fields.to_excel(writer, sheet_name = 'Calculated Fields',index = False)\n",
    "    df_filters.to_excel(writer, sheet_name = 'Filters',index = False)\n",
    "    df_actions.to_excel(writer, sheet_name = 'Actions',index = False)\n",
    "    df_parameters.to_excel(writer, sheet_name = 'Parameters',index = False)\n",
    "    df_refresh_schedule.to_excel(writer, sheet_name = 'Refresh Schedule',index = False)\n",
    "    df_unused_fields.to_excel(writer, sheet_name = 'Unused Fields',index = False)\n",
    "    \n",
    "\n",
    "wb = load_workbook(excel_path)\n",
    "\n",
    "sheet_names = wb.sheetnames\n",
    "\n",
    "manual_cols = ['Ex_Description','Key_Performance_Indicators','Dashboard_Published_Non-Published',\n",
    "               'Server_Name','Database_Name','Schema_Name','Table_View','Custom_SQL','Connection_Type',\n",
    "               'Used','Worksheet_Description',\n",
    "               'Table_Name','Database_Name','Server_Name','Used','SQL_Calculations','Original_Field_Name',\n",
    "               'Metric_Description','Used','Calculation_Type',\n",
    "               'Fields_Used','Sheet_Name',\n",
    "               'Target_Sheet','Target_Filter','Action_Description','Worksheet_Dashboard',\n",
    "               'Parameter_Description','Fields_Used','Used',\n",
    "               'Refresh_Type','Refresh_Schedule','Data_Source_Alias',\n",
    "               'Tableau_Field_Name','Field_Type']\n",
    "\n",
    "\n",
    "for i in sheet_names:\n",
    "    \n",
    "    for cell in wb[i]['1']:\n",
    "\n",
    "        if cell.value in manual_cols:\n",
    "\n",
    "            cell.fill = PatternFill('solid', fgColor = \"00af00\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            cell.fill = PatternFill('solid',fgColor = \"00afff\")\n",
    "\n",
    "wb.save(excel_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
